{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting video encoding...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error saving video: [Errno 22] Invalid argument\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "[Errno 22] Invalid argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 260\u001b[0m\n\u001b[0;32m    257\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsnr\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompression_ratio\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 260\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[16], line 247\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;66;03m# Save reconstructed video for Q=8\u001b[39;00m\n\u001b[0;32m    246\u001b[0m middle_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01mif\u001b[39;00m r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mQ\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m8\u001b[39m)\n\u001b[1;32m--> 247\u001b[0m \u001b[43mcodec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmiddle_result\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreconstructed_frames\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m# Plot results\u001b[39;00m\n\u001b[0;32m    250\u001b[0m codec\u001b[38;5;241m.\u001b[39mplot_results(results)\n",
      "Cell \u001b[1;32mIn[16], line 151\u001b[0m, in \u001b[0;36mVideoCodec.save_video\u001b[1;34m(self, frames, output_path)\u001b[0m\n\u001b[0;32m    148\u001b[0m frame \u001b[38;5;241m=\u001b[39m av\u001b[38;5;241m.\u001b[39mVideoFrame\u001b[38;5;241m.\u001b[39mfrom_ndarray(frame_data, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb24\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    149\u001b[0m frame\u001b[38;5;241m.\u001b[39mpts \u001b[38;5;241m=\u001b[39m i\n\u001b[1;32m--> 151\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m packet \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m    152\u001b[0m     container\u001b[38;5;241m.\u001b[39mmux(packet)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32mav\\\\video\\\\stream.pyx:23\u001b[0m, in \u001b[0;36mav.video.stream.VideoStream.encode\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mav\\\\video\\\\stream.pyx:32\u001b[0m, in \u001b[0;36mav.video.stream.VideoStream.encode\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mav\\\\codec\\\\context.pyx:433\u001b[0m, in \u001b[0;36mav.codec.context.CodecContext.encode\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mav\\\\codec\\\\context.pyx:418\u001b[0m, in \u001b[0;36mav.codec.context.CodecContext._prepare_and_time_rebase_frames_for_encode\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mav\\\\codec\\\\context.pyx:243\u001b[0m, in \u001b[0;36mav.codec.context.CodecContext.open\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mav\\\\error.pyx:326\u001b[0m, in \u001b[0;36mav.error.err_check\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [Errno 22] Invalid argument"
     ]
    }
   ],
   "source": [
    "import av\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class VideoCodec:\n",
    "    def __init__(self, block_size=16, search_radius=8):\n",
    "        self.block_size = block_size\n",
    "        self.search_radius = search_radius\n",
    "        \n",
    "    def read_video(self, input_path):\n",
    "        \"\"\"Read video file and extract RGB frames\"\"\"\n",
    "        try:\n",
    "            container = av.open(input_path)\n",
    "            frames = []\n",
    "            total_frames = container.streams.video[0].frames\n",
    "            # Get video parameters for saving later\n",
    "            self.fps = container.streams.video[0].average_rate\n",
    "            self.width = container.streams.video[0].width\n",
    "            self.height = container.streams.video[0].height\n",
    "            \n",
    "            logger.info(f\"Reading {total_frames} frames...\")\n",
    "            \n",
    "            for i, frame in enumerate(container.decode(video=0)):\n",
    "                # Convert frame to numpy array in RGB format\n",
    "                img = frame.to_ndarray(format='rgb24')\n",
    "                # Ensure correct data type\n",
    "                img = img.astype(np.float32)\n",
    "                frames.append(img)\n",
    "                \n",
    "                # Log progress\n",
    "                if i % 10 == 0:\n",
    "                    logger.info(f\"Processed {i}/{total_frames} frames\")\n",
    "            \n",
    "            logger.info(\"Video reading completed\")\n",
    "            return frames\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading video: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def logarithmic_search(self, curr_block, ref_frame, x, y, channel):\n",
    "        \"\"\"Logarithmic search for motion estimation for a single channel\"\"\"\n",
    "        best_x, best_y = x, y\n",
    "        best_sat = float('inf')\n",
    "        step = self.search_radius\n",
    "        \n",
    "        while step >= 1:\n",
    "            for dx in [-step, 0, step]:\n",
    "                for dy in [-step, 0, step]:\n",
    "                    new_x = x + dx\n",
    "                    new_y = y + dy\n",
    "                    \n",
    "                    if (new_x < 0 or new_x + self.block_size > ref_frame.shape[1] or\n",
    "                        new_y < 0 or new_y + self.block_size > ref_frame.shape[0]):\n",
    "                        continue\n",
    "                        \n",
    "                    ref_block = ref_frame[new_y:new_y+self.block_size, \n",
    "                                        new_x:new_x+self.block_size, channel]\n",
    "                    sat = np.sum(np.abs(curr_block - ref_block))\n",
    "                    \n",
    "                    if sat < best_sat:\n",
    "                        best_sat = sat\n",
    "                        best_x = new_x\n",
    "                        best_y = new_y\n",
    "            \n",
    "            step //= 2\n",
    "            \n",
    "        return best_x - x, best_y - y\n",
    "    \n",
    "    def motion_estimation(self, curr_frame, ref_frame):\n",
    "        \"\"\"Perform motion estimation using logarithmic search for RGB frames\"\"\"\n",
    "        height, width = curr_frame.shape[:2]\n",
    "        mv_x = np.zeros((height//self.block_size, width//self.block_size))\n",
    "        mv_y = np.zeros((height//self.block_size, width//self.block_size))\n",
    "        \n",
    "        # Use luminance (approximated from RGB) for motion estimation\n",
    "        curr_y = 0.299 * curr_frame[:,:,0] + 0.587 * curr_frame[:,:,1] + 0.114 * curr_frame[:,:,2]\n",
    "        ref_y = 0.299 * ref_frame[:,:,0] + 0.587 * ref_frame[:,:,1] + 0.114 * ref_frame[:,:,2]\n",
    "        \n",
    "        for i in range(0, height-self.block_size+1, self.block_size):\n",
    "            for j in range(0, width-self.block_size+1, self.block_size):\n",
    "                curr_block = curr_y[i:i+self.block_size, j:j+self.block_size]\n",
    "                dx, dy = self.logarithmic_search(curr_block, ref_y, j, i, None)\n",
    "                mv_x[i//self.block_size, j//self.block_size] = dx\n",
    "                mv_y[i//self.block_size, j//self.block_size] = dy\n",
    "                \n",
    "        return mv_x, mv_y\n",
    "    \n",
    "    def motion_compensation(self, ref_frame, mv_x, mv_y):\n",
    "        \"\"\"Perform motion compensation using motion vectors for RGB frames\"\"\"\n",
    "        height, width = ref_frame.shape[:2]\n",
    "        compensated = np.zeros_like(ref_frame)\n",
    "        \n",
    "        for i in range(mv_x.shape[0]):\n",
    "            for j in range(mv_x.shape[1]):\n",
    "                ref_x = j * self.block_size + int(mv_x[i, j])\n",
    "                ref_y = i * self.block_size + int(mv_y[i, j])\n",
    "                \n",
    "                if (ref_x >= 0 and ref_x + self.block_size <= width and\n",
    "                    ref_y >= 0 and ref_y + self.block_size <= height):\n",
    "                    compensated[i*self.block_size:(i+1)*self.block_size,\n",
    "                            j*self.block_size:(j+1)*self.block_size] = \\\n",
    "                        ref_frame[ref_y:ref_y+self.block_size,\n",
    "                                ref_x:ref_x+self.block_size]\n",
    "                        \n",
    "        return compensated\n",
    "    \n",
    "    def quantize(self, data, Q):\n",
    "        \"\"\"Quantize the data with step size Q\"\"\"\n",
    "        return np.round(data / Q) * Q\n",
    "    \n",
    "    def compute_psnr(self, original, compressed):\n",
    "        \"\"\"Compute PSNR between original and compressed RGB frames\"\"\"\n",
    "        mse = np.mean((original - compressed) ** 2)\n",
    "        if mse < 1e-10:\n",
    "            return 100.0\n",
    "        max_pixel = 255.0\n",
    "        psnr = 20 * np.log10(max_pixel / np.sqrt(mse))\n",
    "        return psnr\n",
    "    \n",
    "    def save_video(self, frames, output_path):\n",
    "        \"\"\"Save reconstructed frames as AVI video\"\"\"\n",
    "        try:\n",
    "            # Открываем выходной контейнер\n",
    "            container = av.open(output_path, mode='w')\n",
    "            \n",
    "            # Создаем видеопоток с корректными параметрами\n",
    "            stream = container.add_stream('mpeg4', rate=int(self.fps))\n",
    "            stream.width = self.width\n",
    "            stream.height = self.height\n",
    "            stream.pix_fmt = 'yuv420p'\n",
    "            \n",
    "            # Установим битрейт\n",
    "            stream.bit_rate = 1000000  # 1 Mbps\n",
    "            # Установим другие важные параметры\n",
    "            stream.time_base = 1/self.fps\n",
    "            \n",
    "            logger.info(f\"Saving {len(frames)} frames to {output_path}\")\n",
    "            \n",
    "            for i, frame_data in enumerate(frames):\n",
    "                # Ensure frame data is in uint8 format and correct range\n",
    "                frame_data = np.clip(frame_data, 0, 255).astype(np.uint8)\n",
    "                \n",
    "                # Create VideoFrame\n",
    "                frame = av.VideoFrame.from_ndarray(frame_data, format='rgb24')\n",
    "                frame.pts = i\n",
    "                \n",
    "                for packet in stream.encode(frame):\n",
    "                    container.mux(packet)\n",
    "                \n",
    "                if i % 10 == 0:\n",
    "                    logger.info(f\"Saved frame {i}/{len(frames)}\")\n",
    "            \n",
    "            # Flush the stream\n",
    "            for packet in stream.encode(None):\n",
    "                container.mux(packet)\n",
    "            \n",
    "            # Close the container\n",
    "            container.close()\n",
    "            logger.info(\"Video saving completed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving video: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def encode_video(self, input_path, q_values):\n",
    "        \"\"\"Encode video with different quantization steps\"\"\"\n",
    "        frames = self.read_video(input_path)\n",
    "        results = []\n",
    "        \n",
    "        for Q in q_values:\n",
    "            logger.info(f\"Processing with quantization step Q={Q}\")\n",
    "            psnr_values = []\n",
    "            compression_ratios = []\n",
    "            diff_frames = []\n",
    "            reconstructed_frames = []\n",
    "            \n",
    "            for i in range(1, len(frames)):\n",
    "                # Motion estimation\n",
    "                mv_x, mv_y = self.motion_estimation(frames[i], frames[i-1])\n",
    "                \n",
    "                # Motion compensation\n",
    "                predicted = self.motion_compensation(frames[i-1], mv_x, mv_y)\n",
    "                \n",
    "                # Residual\n",
    "                residual = frames[i] - predicted\n",
    "                \n",
    "                # Quantization with scaling for each channel\n",
    "                scaled_residual = residual / 255.0\n",
    "                quantized_residual = self.quantize(scaled_residual, Q/255.0)\n",
    "                residual_reconstructed = quantized_residual * 255.0\n",
    "                \n",
    "                # Reconstruction\n",
    "                reconstructed = predicted + residual_reconstructed\n",
    "                reconstructed = np.clip(reconstructed, 0, 255)\n",
    "                \n",
    "                # Calculate metrics\n",
    "                psnr = self.compute_psnr(frames[i], reconstructed)\n",
    "                psnr_values.append(psnr)\n",
    "                \n",
    "                # Store frames\n",
    "                diff_frames.append(residual)\n",
    "                reconstructed_frames.append(reconstructed)\n",
    "                \n",
    "                # Estimate compression ratio (considering all channels)\n",
    "                orig_size = frames[i].size * 8\n",
    "                mv_bits = (mv_x.size + mv_y.size) * 8\n",
    "                residual_bits = np.count_nonzero(quantized_residual) * 8\n",
    "                compressed_size = mv_bits + residual_bits\n",
    "                compression_ratio = orig_size / (compressed_size + 1)\n",
    "                compression_ratios.append(compression_ratio)\n",
    "                \n",
    "                if i % 10 == 0:\n",
    "                    logger.info(f\"Processed frame {i}/{len(frames)-1} for Q={Q}\")\n",
    "            \n",
    "            results.append({\n",
    "                'Q': Q,\n",
    "                'psnr': np.mean(psnr_values),\n",
    "                'compression_ratio': np.mean(compression_ratios),\n",
    "                'diff_frames': diff_frames,\n",
    "                'reconstructed_frames': reconstructed_frames\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "\n",
    "def main():\n",
    "    # Initialize codec\n",
    "    codec = VideoCodec(block_size=16, search_radius=8)\n",
    "    \n",
    "    # Input and output video paths\n",
    "    input_path = \"lr1_1.avi\"\n",
    "    output_path = \"output.avi\"  # Изменено имя выходного файла\n",
    "    \n",
    "    # Define quantization steps\n",
    "    q_values = [1, 4, 8, 16, 32]\n",
    "    \n",
    "    print(\"Starting video encoding...\")\n",
    "    \n",
    "    # Encode video\n",
    "    results = codec.encode_video(input_path, q_values)\n",
    "    \n",
    "    # Save reconstructed video for Q=8\n",
    "    middle_result = next(r for r in results if r['Q'] == 8)\n",
    "    codec.save_video(middle_result['reconstructed_frames'], output_path)\n",
    "    \n",
    "    # Plot results\n",
    "    codec.plot_results(results)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nEncoding Results:\")\n",
    "    print(\"Q\\tPSNR (dB)\\tCompression Ratio\")\n",
    "    print(\"-\" * 40)\n",
    "    for result in results:\n",
    "        print(f\"{result['Q']}\\t{result['psnr']:.2f}\\t\\t{result['compression_ratio']:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
